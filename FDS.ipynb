{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**FDS LAB  ALL ASSIGNMENT CODES**"
      ],
      "metadata": {
        "id": "LtzTn0e1jIt_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuFefRRBjAxZ"
      },
      "outputs": [],
      "source": [
        "# -Assignment 1\n",
        "# -Name: Vivesh G\n",
        "'''\n",
        "- Function Name: mean\n",
        "- Purpose: To calculate mean of numbers in a list\n",
        "- Arguments: nums is a list containing integers\n",
        "- Return Value: Mean value, a float is returned\n",
        "'''\n",
        "def mean(nums):\n",
        "   total = 0.0\n",
        "   for num in nums:\n",
        "       total = total + num\n",
        "   return total/len(nums)\n",
        "\n",
        "'''\n",
        "- Function Name: median\n",
        "- Purpose: To calculate median of numbers in a list\n",
        "- Arguments: nums is a list containing integers\n",
        "- Return Value: Median value, a float is returned\n",
        "'''\n",
        "def median(nums):\n",
        "   nums.sort()\n",
        "   n = len(nums)\n",
        "   if n % 2 == 1:\n",
        "      return nums[n//2]\n",
        "   else:\n",
        "      return (nums[n//2 - 1] + nums[n//2]) / 2\n",
        "\n",
        "'''\n",
        "- Function Name: mode\n",
        "- Purpose: To calculate mode of numbers in a list.Mode is the number which occurs most frequently\n",
        "- Arguments: nums is a list containing integers\n",
        "- Return Value: mode value, a number in the list is returned\n",
        "'''\n",
        "def mode(nums):\n",
        "   frequency = {}\n",
        "   for num in nums:\n",
        "       if num in frequency:\n",
        "           frequency[num] += 1\n",
        "       else:\n",
        "           frequency[num] = 1\n",
        "   max_frequency = max(frequency.values())\n",
        "   modes = [num for num, freq in frequency.items() if freq == max_frequency]\n",
        "   return modes\n",
        "\n",
        "'''\n",
        "- Function Name: variance\n",
        "- Purpose: To calculate the variance of numbers in a list\n",
        "- Arguments: nums is a list containing integers. mean is the mean value of the numbers\n",
        "- Return Value: variance value, a float is returned\n",
        "'''\n",
        "def variance(nums,mean):\n",
        "   sum = 0\n",
        "   for num in nums:\n",
        "       sum += (num - mean)**2\n",
        "   return sum/(len(nums)-1)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    data = [50,30,20,60,90,10,40,30,10]\n",
        "    mean = mean(data)\n",
        "    print(\"Mean is \",mean)\n",
        "    print(\"Median is \",median(data))\n",
        "    print(\"Mode is \",mode(data))\n",
        "    print(\"Variance is \",variance(data,mean))\n",
        "    print(\"Standard Deviation is \",variance(data,mean)**0.5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Assignment 2: NumPy Exercises\n",
        "Name: Vivesh G\n",
        "'''\n",
        "import numpy as np\n",
        "'''\n",
        "- Function Name: add\n",
        "- Purpose: To add two 1-D numpy vectors element-wise\n",
        "- Arguments: a and b are single dimension numpy vectors of type int32\n",
        "- Return Value: result is a single dimension numpy vector of type int 32\n",
        "'''\n",
        "\n",
        "def add(a,b):\n",
        "    result = np.array([])\n",
        "    for i in range(a.shape[0]):\n",
        "        result = np.append(result,a[i] + b[i])\n",
        "    return result\n",
        "\n",
        "def dot_product(a,b):\n",
        "    result = 0\n",
        "    for i in range(a.shape[0]):\n",
        "        result = result + a[i]*b[i]\n",
        "    return result\n",
        "\n",
        "def mat_add(a,b):\n",
        "    result = np.zeros(a.shape)\n",
        "    for i in range(a.shape[0]):\n",
        "        for j in range(a.shape[1]):\n",
        "            result[i][j] = a[i][j] + b[i][j]\n",
        "    return np.array(result)\n",
        "\n",
        "def mat_mul(a,b):\n",
        "    result = []\n",
        "    for i in range(len(a)):\n",
        "        row = []\n",
        "        for j in range(len(b[0])):\n",
        "            res = 0\n",
        "            for k in range(len(b)):\n",
        "                res += a[i][k] * b[k][j]\n",
        "            row.append(res)\n",
        "        result.append(row)\n",
        "    return np.array(result)\n",
        "\n",
        "def check(a,b):\n",
        "    if a.shape[1] == b.shape[0]:\n",
        "        return mat_mul(a,b)\n",
        "    else:\n",
        "        print(\"Matrix Cannot be Multiplied\")\n",
        "\n",
        "vec_1 = np.array([1,2,3])\n",
        "vec_2 = np.array([4,5,6])\n",
        "vec_3 = np.array([[1,2,5],[5,2,3],[1,1,1]])\n",
        "vec_4 = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
        "print(add(vec_1,vec_2))\n",
        "print(dot_product(vec_1,vec_2))\n",
        "print(mat_add(vec_3,vec_4))\n",
        "print(check(vec_3,vec_4))"
      ],
      "metadata": {
        "id": "YRJErjVXnWBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -Assignment 3\n",
        "# -Name: Vivesh G\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# -Importing data from csv files into pandas DataFrame.\n",
        "df1 = pd.read_csv(\"part11.csv\") #Names1\n",
        "df2 = pd.read_csv(\"part12.csv\") #Marks1\n",
        "df3 = pd.read_csv(\"part21.csv\") #Names2\n",
        "df4 = pd.read_csv(\"part22.csv\") #Marks2\n",
        "\n",
        "# -To check the definitions of the DataFrames created.\n",
        "df1.info()\n",
        "df2.info()\n",
        "df3.info()\n",
        "df4.info()\n",
        "\n",
        "'''\n",
        "- Merging the 4 DataFrames into a single DataFrame.\n",
        "- concat method is used here. The DataFrames containing similar data are concatened on axis 0 (vertically).\n",
        "- The concatenated DataFrames are saved to a new DataFrame.\n",
        "- Then the 2 DataFrames are concatenated on axis 1 (horizontally) to create a single DataFrame.\n",
        "'''\n",
        "merged_pd1 = pd.concat([df1,df3], axis=0, ignore_index=True)\n",
        "merged_pd2 = pd.concat([df2,df4], axis=0, ignore_index=True)\n",
        "merged_df = pd.concat([merged_pd1,merged_pd2], axis=1)\n",
        "merged_df.info()\n",
        "\n",
        "'''\n",
        "- Replacing NaN values with zeroes\n",
        "'''\n",
        "merged_df.replace('A',0,inplace=True)\n",
        "print(merged_df)\n",
        "merged_df.to_csv('merged.csv')\n",
        "merged_df[['CAT1','CAT2','CAT3']] = merged_df[['CAT1','CAT2','CAT3']].astype('int32')\n",
        "merged_df.info()\n",
        "\n",
        "'''\n",
        "- Summary Statistics\n",
        "- Adding grace Marks to CAT3\n",
        "'''\n",
        "merged_df.describe()\n",
        "merged_df['CAT3'] = merged_df.apply(lambda row: row['CAT3'] + 5 if row['CAT3'] < 50 else row['CAT3'], axis=1)\n",
        "merged_df.head()\n",
        "\n",
        "'''\n",
        "- Function Name: top_two\n",
        "- Arguments: l <class-list>\n",
        "- Purpose: To return the average of 2 maximum values in the list\n",
        "- Return values: average of 2 max values\n",
        "- Return Type: float\n",
        "'''\n",
        "def average_top_two(l):\n",
        "    max_1 = l[0]\n",
        "    max_2 = l[1]\n",
        "    for i in l:\n",
        "        if (max_1 < i and max_2 < i):\n",
        "            max_2 = max_1\n",
        "            max_1 = i\n",
        "        elif (max_2 < i and max_1 > i ):\n",
        "            max_2 = i\n",
        "    return (max_1 + max_2)/2\n",
        "\n",
        "'''\n",
        "- Calculate Internal Marks and merge it into DataFrame\n",
        "'''\n",
        "Internal = []\n",
        "for i in range(len(merged_df)):\n",
        "    temp = []\n",
        "    temp.append(merged_df.iat[i,2])\n",
        "    temp.append(merged_df.iat[i,3])\n",
        "    temp.append(merged_df.iat[i,4])\n",
        "    Internal.append(average_top_two(temp))\n",
        "merged_df['Internal'] = Internal\n",
        "print(merged_df)\n",
        "print(merged_df.info())\n",
        "\n",
        "'''\n",
        "- The instructor changes her mind about having added grace marks. She wants to wants to undo the addition of grace mark in the earlier step. Instead, she now wants to add a grace mark only to those whose internal mark is below 50.\n",
        "'''\n",
        "merged_df.loc[(merged_df['CAT3'] < 55), 'CAT3'] -= 5\n",
        "merged_df['Internal'] = merged_df.apply(lambda row: row['Internal'] + 5 if row['Internal'] < 50 else row['Internal'], axis=1)\n",
        "merged_df.head()\n",
        "'''\n",
        "- Generate Random values for End Semester and merge it into DataFrame\n",
        "'''\n",
        "ESE = []\n",
        "for i in range(len(merged_df)):\n",
        "    ESE.append(random.randint(50,100))\n",
        "merged_df['ESE'] = ESE\n",
        "print(merged_df)\n",
        "\n",
        "'''\n",
        "- Calculate Total Marks and Assign Grade\n",
        "'''\n",
        "Total = []\n",
        "Grade = []\n",
        "for i in range(len(merged_df)):\n",
        "    Total.append((int(merged_df.iat[i,5])+int(merged_df.iat[i,6]))/2)\n",
        "    if Total[i]>=90 and Total[i]<=100:\n",
        "        Grade.append('O')\n",
        "    elif Total[i]>=80 and Total[i]<90:\n",
        "        Grade.append('A')\n",
        "    elif Total[i]>=70 and Total[i]<80:\n",
        "        Grade.append('B')\n",
        "    elif Total[i]>50 and Total[i]<70:\n",
        "        Grade.append('C')\n",
        "    else:\n",
        "        Grade.append('F')\n",
        "merged_df['Total'] = Total\n",
        "merged_df['Grade'] = Grade\n",
        "print(merged_df)\n",
        "merged_df.to_csv('merged.csv')"
      ],
      "metadata": {
        "id": "NkWKqsVOnl-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Created on Sat Mar 23 10:32:24 2024\n",
        "@author: vivesh\n",
        "\"\"\"\n",
        "# %%\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "# %%\n",
        "data_set = pd.read_csv(\"IPL_Matches_2008_2022.csv\")\n",
        "data_set.info()\n",
        "# %%\n",
        "'''\n",
        "group_wickets = data_set.groupby([\"WonBy\"])\n",
        "group_runs = data_set.groupby([\"WonBy\"])\n",
        "group_wickets.describe()'''\n",
        "# %%\n",
        "df1 = data_set[data_set[\"WonBy\"]== 'Wickets'][['WonBy','Margin']]\n",
        "df2 = data_set[data_set[\"WonBy\"]== 'Runs'][['WonBy','Margin']]\n",
        "# %%\n",
        "print(\"Mean = \",df1['Margin'].mean())\n",
        "print(\"Median = \",df1['Margin'].median())\n",
        "print(\"Mode = \",df1['Margin'].mode())\n",
        "print(\"Variance = \",df1['Margin'].var())\n",
        "print(\"Standard Deviation = \",df1['Margin'].std())\n",
        "# %%\n",
        "print(\"Mean = \",df2['Margin'].mean())\n",
        "print(\"Median = \",df2['Margin'].median())\n",
        "print(\"Mode = \",df2['Margin'].mode())\n",
        "print(\"Variance = \",df2['Margin'].var())\n",
        "print(\"Standard Deviation = \",df2['Margin'].std())\n"
      ],
      "metadata": {
        "id": "P99ERLD6o5ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Assignment 5 Sampling\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sample1 = np.random.normal(loc = 100, scale = 15,size = 10).astype('int')\n",
        "sample2 = np.random.normal(loc = 100, scale = 15,size = 100).astype('int')\n",
        "sample3 = np.random.normal(loc = 100, scale = 15,size = 1000).astype('int')\n",
        "\n",
        "mean_s1 = np.mean(sample1)\n",
        "std_s1 = np.std(sample1)\n",
        "mean_s2 = np.mean(sample2)\n",
        "std_s2 = np.std(sample2)\n",
        "mean_s3 = np.mean(sample3)\n",
        "std_s3 = np.std(sample3)\n",
        "\n",
        "print(f\"Sample1 mean ={mean_s1}, dtandard deviation = {std_s1}\")\n",
        "print(f\"Sample2 mean ={mean_s2}, dtandard deviation = {std_s2}\")\n",
        "print(f\"Sample3 mean ={mean_s3}, dtandard deviation = {std_s3}\")\n",
        "\n",
        "n = 5\n",
        "sample = np.random.normal(loc = 100, scale = 15, size = 5)\n",
        "print(sample)\n",
        "print(f\"Mean = {np.mean(sample)}\")\n",
        "\n",
        "for i in range(10):\n",
        "    sample = np.random.normal(loc = 100, scale = 15, size = 5)\n",
        "    print(sample)\n",
        "    print(f\"Mean = {np.mean(sample)}\")\n",
        "\n",
        "mean_list_s1 = []\n",
        "mean_list_s2 = []\n",
        "mean_list_s3 = []\n",
        "for i in range(10000):\n",
        "    s1 = np.random.normal(loc = 100, scale = 15, size = 1).astype('int')\n",
        "    s2 = np.random.normal(loc = 100, scale = 15, size = 2).astype('int')\n",
        "    s3 = np.random.normal(loc = 100, scale = 15, size = 10).astype('int')\n",
        "    #print(s1)\n",
        "    Mean1 = np.mean(s1)\n",
        "    Mean2 = np.mean(s2)\n",
        "    Mean3 = np.mean(s3)\n",
        "    #print(f\"Mean = {Mean}\")\n",
        "    mean_list_s1.append(Mean1)\n",
        "    mean_list_s2.append(Mean2)\n",
        "    mean_list_s3.append(Mean3)\n",
        "fig, (axs1, axs2, axs3) = plt.subplots(1,3, figsize=(15, 6))\n",
        "axs1.hist(mean_list_s1, bins = 50)\n",
        "axs1.set_xlabel('Mean')\n",
        "axs1.set_ylabel('Frequency')\n",
        "axs1.set_title('Histogram n = 1')\n",
        "axs2.hist(mean_list_s2, bins = 50)\n",
        "axs2.set_xlabel('Mean')\n",
        "axs2.set_ylabel('Frequency')\n",
        "axs2.set_title('Histogram n = 2')\n",
        "axs3.hist(mean_list_s3, bins = 50)\n",
        "axs3.set_xlabel('Mean')\n",
        "axs3.set_ylabel('Frequency')\n",
        "axs3.set_title('Histogram n = 3')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uGrjw0Hmnyo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Assignment 6 Bootstrap\n",
        "from scipy.stats import bootstrap\n",
        "import numpy as np\n",
        "\n",
        "#convert array to sequence\n",
        "data = (data,)\n",
        "\n",
        "#calculate 95% bootstrapped confidence interval for median\n",
        "bootstrap_ci = bootstrap(data, np.median, confidence_level=0.95,\n",
        "                         random_state=1, method='percentile')\n",
        "\n",
        "#view 95% boostrapped confidence interval\n",
        "print(bootstrap_ci.confidence_interval)"
      ],
      "metadata": {
        "id": "GaJOojh2pMED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ASSIGNMENT 7 AND 8\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#Reading the data File\n",
        "Anor = pd.read_csv('http://stat4ds.rwth-aachen.de/data/Anorexia.dat', sep='\\s+')\n",
        "Anor.head(3)\n",
        "Anor['change'] = Anor['after'] - Anor['before'] #Creating column change\n",
        "Anor.loc[Anor['therapy'] == 'cb']['change'].describe() #Summary Statistics of chnage where therapy is cb\n",
        "#Printing Histogram\n",
        "bins=list(range(-10,30,2))\n",
        "plt.hist(Anor.loc[Anor['therapy']=='cb']['change'],bins, edgecolor='k')\n",
        "plt.xlabel('Weight change'); plt.ylabel('Frequency')\n",
        "#Calculating Confidence Intervals using stats model\n",
        "changeCB = Anor.loc[Anor['therapy'] == 'cb']['change']\n",
        "import statsmodels.stats.api as sms\n",
        "print(sms.DescrStatsW(changeCB).tconfint_mean())\n",
        "print(sms.DescrStatsW(changeCB).tconfint_mean(alpha=0.01))\n",
        "\n",
        "import os\n",
        "Books = pd.read_csv('http://stat4ds.rwth-aachen.de/data/Library.dat', sep='\\s+')\n",
        "Books.head(3)\n",
        "Books.describe()\n",
        "print(np.median(Books['C']))\n",
        "print(np.median(Books['P']))\n",
        "plt.boxplot(Books[\"P\"], vert=False) # Box plot of P without outliers\n",
        "plt.xlabel(\"Years since publication\")\n",
        "plt.boxplot(Books[\"P\"], vert=False, showfliers=False) #Boxplot without Outliers\n",
        "plt.xlabel(\"Years since publication\")\n",
        "import bootstrapped.bootstrap as bs\n",
        "import bootstrapped.stats_functions as bs_stats\n",
        "population = Books[\"P\"]\n",
        "samples = np.array(population[:]) #Taking samples for bootstrapping\n",
        "print(bs.bootstrap(samples, stat_func=bs_stats.median)) #Bootstrapped median\n",
        "print(bs.bootstrap(samples, stat_func=bs_stats.std)) #Bootstrapped standard deviation"
      ],
      "metadata": {
        "id": "ZlsgWDHgpO-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ASSIGNMENT 9 HYPOTHESIS TESTING\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd. read_csv(\"ACCIDENTS_GU_BCN_2010.csv\", encoding='latin -1')\n",
        "# Create a new column which is the date\n",
        "data['Date'] = data['Dia de mes']. apply ( lambda x: str(x)) + '-' + data['Mes de any']. apply ( lambda x: str(x))\n",
        "data2 = data['Date']\n",
        "print(data2.head())\n",
        "counts2010 = data['Date'].value_counts()\n",
        "print (f'2010: Mean {counts2010. mean()}')\n",
        "data = pd. read_csv(\"ACCIDENTS_GU_BCN_2013.csv\", encoding='latin -1')\n",
        "# Create a new column which is the date\n",
        "data['Date'] = data['Dia de mes']. apply ( lambda x: str(x)) + '-' + data['Mes de any']. apply ( lambda x: str(x))\n",
        "data2 = data['Date']\n",
        "counts2013 = data['Date'].value_counts()\n",
        "print(f'2013: Mean {counts2013. mean()}')\n",
        "n = len(counts2013)\n",
        "mean = counts2013. mean()\n",
        "s = counts2013.std()\n",
        "ci = [mean - s*1.96/np.sqrt(n), mean + s*1.96/np.sqrt (n)]\n",
        "print (f'2010 accident rate estimate: {counts2010. mean()}')\n",
        "print (f'2013 accident rate estimate: {counts2013. mean()}')\n",
        "print (f'CI for 2013: {ci}')\n",
        "m = len(counts2010)\n",
        "n = len(counts2013)\n",
        "p = (counts2013. mean() - counts2010. mean())\n",
        "print (f'm: {m}, n: {n}')\n",
        "print (f'mean difference: â€™ {p}')\n",
        "#Pooling Distribution\n",
        "x = counts2010\n",
        "y = counts2013\n",
        "pool = np. concatenate([x, y])\n",
        "np.random. shuffle(pool)\n",
        "import random\n",
        "N = 10000 # number of samples\n",
        "diff = range (N)\n",
        "for i in range (N):\n",
        "  p1 = np.array([random.choice(pool) for _ in range (n)])\n",
        "  p2 = np.array([random.choice(pool) for _ in range (n)])\n",
        "  diff[i] = (np.mean(p1) - np.mean(p2))\n",
        "  diff2 = np.array(diff)\n",
        "  w1 = np.where(diff2 > p)[0]\n",
        "print('p-value ( Simulation)=', len(w1)/ float (N),'(', len(w1)/ float (N)*100 ,'%)', 'Difference =', p)\n",
        "if ( len(w1)/ float (N)) < 0.05:\n",
        "  print ('The effect is likely')\n",
        "else :\n",
        "  print ('The effect is not likely')"
      ],
      "metadata": {
        "id": "rzV5KLO7pyzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ASSIGNMENT 10, 11 - MACHINE LEARNING\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "#LINEAR REGRESSION\n",
        "d_x,d_y = datasets.load_diabetes(return_X_y=True)\n",
        "#print(d_x)\n",
        "#print(d_y)\n",
        "d_x = d_x[:,np.newaxis,2]\n",
        "print(d_x)\n",
        "d_x_train = d_x[:-10]\n",
        "d_x_test = d_x[-10:]\n",
        "#print(d_x_train)\n",
        "#print(d_x_test)\n",
        "d_y_train = d_y[:-10]\n",
        "d_y_test = d_y[-10:]\n",
        "#print(d_y_train)\n",
        "#print(d_y_test)\n",
        "regr = linear_model.LinearRegression()\n",
        "regr.fit(d_x_train, d_y_train)\n",
        "d_y_pred = regr.predict(d_x_test)\n",
        "print(f\"Coefficients: \\n {regr.coef_}\")\n",
        "print(f\"Mean squared error: {mean_squared_error(d_y_test, d_y_pred)}\")\n",
        "print(f\"Coefficient of determination: {r2_score(d_y_test, d_y_pred)}\")\n",
        "plt.scatter(d_x_test, d_y_test, color=\"black\")\n",
        "plt.plot(d_x_test, d_y_pred, color=\"blue\", linewidth=3)\n",
        "\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jn6QYGCBqP8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN - NEAREST NEIGHBOUR CLASSIFICATION\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np\n",
        "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
        "nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(X)\n",
        "distances, indices = nbrs.kneighbors(X)\n",
        "print(indices)\n",
        "print(distances)\n",
        "nbrs.kneighbors_graph(X).toarray()"
      ],
      "metadata": {
        "id": "xHi8vgARq57x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LOGISTIC REGRESSION\n",
        "from sklearn. linear_model import LogisticRegression\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = pd. read_csv('SP1.csv')\n",
        "s = data[[ 'HomeTeam','AwayTeam', 'FTHG', 'FTAG', 'FTR']]\n",
        "\n",
        "def my_f1(row):\n",
        "  return max(row['FTHG'], row['FTAG'])\n",
        "def my_f2(row):\n",
        "  return min(row['FTHG'], row['FTAG'])\n",
        "\n",
        "s ['W'] = s. apply (my_f1 , axis = 1)\n",
        "s ['L'] = s. apply (my_f2 , axis = 1)\n",
        "x1 = s['W'].values\n",
        "y1 = np.ones( len(x1), dtype = np.int32)\n",
        "x2 = s['L'].values\n",
        "y2 = np.zeros( len(x2), dtype = np.int32)\n",
        "x = np.concatenate ([x1 , x2])\n",
        "x = x[:, np.newaxis]\n",
        "y = np.concatenate ([y1 , y2])\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(x, y)\n",
        "X_test = np.linspace(-5, 10, 300)\n",
        "\n",
        "def lr_model (x):\n",
        "  return 1 / (1+np.exp(-x))\n",
        "\n",
        "loss = lr_model(X_test*logreg.coef_ + logreg. intercept_).ravel()\n",
        "X_test2 = X_test[:,np.newaxis]\n",
        "losspred = logreg.predict(X_test2)\n",
        "plt.scatter(x.ravel(), y,color = 'black',s = 100, zorder = 20,alpha = 0.03)\n",
        "plt.plot(X_test , loss , color = 'blue', linewidth = 3)\n",
        "plt.plot(X_test , losspred , color = 'red', linewidth = 3)"
      ],
      "metadata": {
        "id": "etkkcXkrrEXz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}